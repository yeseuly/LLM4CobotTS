# LLM4CobotTS
LLM4CobotTS is a framework for analyzing collaborative robot (cobot) time-series data using Large Language Models (LLMs). This project explores natural languageâ€“driven interpretation, anomaly detection, and task-specific insights from multi-sensor robotic data streams.


### - Developers ğŸ‘©â€ğŸ’»

- **Ye-Seul Park**  
  âœ‰ï¸ [yeseuly777@gmail.com](mailto:yeseuly777@gmail.com)

- **Minseo Choi**  
  âœ‰ï¸ [minseo000624@gmail.com](mailto:minseo000624@gmail.com)

---

## ğŸ”§ Environment Variables

| Name | Default | Description |
|---|---:|---|
| `OPENAI_API_KEY` | â€” | OpenAI API Key (í•„ìˆ˜) |
| `OPENAI_MODEL` | `gpt-4o-mini` | LangChain `ChatOpenAI`ì— ì‚¬ìš©í•  ëª¨ë¸ |
| `OPENAI_CHAT_MODEL` | `gpt-4o` | OpenAI Python SDK(ì €ìˆ˜ì¤€)ì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ |
| `OPENAI_TEMPERATURE` | `0` | (LangChain) ì‘ë‹µ ì°½ì˜ì„± |
| `OPENAI_TOP_P` | `1.0` | (LangChain) nucleus sampling |
| `OPENAI_MAX_TOKENS` | `2048` | (LangChain) ìµœëŒ€ í† í° ìˆ˜ |

---

## ğŸš€ Quick Start â€” Chat with your cobot data (using project modules)

ë³¸ ì˜ˆì œëŠ” ë ˆí¬ì— í¬í•¨ëœ ëª¨ë“ˆë§Œ ì‚¬ìš©í•˜ì—¬,  
1) ë°ì´í„°ë¥¼ ë¡œë“œ/ì „ì²˜ë¦¬í•˜ê³   
2) LLMì—ê²Œ ì§ˆë¬¸ì„ ë˜ì ¸  
3) ê²°ê³¼ë¥¼ ëŒ€í™”í˜•ìœ¼ë¡œ ë°›ì•„ë³´ëŠ” **ê°„ë‹¨ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤**ì…ë‹ˆë‹¤.

---

### 0) Install & Env

```bash
pip install -r requirements.txt
```

.env íŒŒì¼(ë£¨íŠ¸ ê²½ë¡œ)ì— OpenAI í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”:
```ini
OPENAI_API_KEY=sk-********************************
# (ì„ íƒ) ëª¨ë¸/ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_CHAT_MODEL=gpt-4o
# OPENAI_TEMPERATURE=0.3
# OPENAI_TOP_P=0.9
# OPENAI_MAX_TOKENS=1200
```

### 1) One-shot: Ask once about your dataset
ì•„ë˜ ìŠ¤ë‹ˆí«ì„ examples/ask_once.pyë¡œ ì €ì¥ í›„ ì‹¤í–‰í•˜ë©´,
ë°ì´í„°ë¥¼ ë¡œë“œâ†’ì „ì²˜ë¦¬í•œ ë’¤ í•œ ë²ˆ ì§ˆë¬¸í•˜ê³  ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤.

```python
# examples/ask_once.py
from modules.data_loader import load_cobot_data
from modules.preprocessor import preprocess_pipeline
from modules.llm_analyzer import analyze_with_llm

# 1) Load & preprocess
DF_PATH = "data/cobot-sample.csv"  # <- ë°ì´í„° ê²½ë¡œë¥¼ ìƒí™©ì— ë§ê²Œ ìˆ˜ì •
df = load_cobot_data(DF_PATH)
df_prep = preprocess_pipeline(df)

# 2) Ask LLM about the dataset
question = "Identify anomalies in q/qdot and any signs of torque saturation."
report = analyze_with_llm(
    df_prep,
    prompt=question,
    rows=10,           # í”„ë¦¬ë·°ë¡œ ë³´ë‚¼ ì´ í–‰ ìˆ˜ (head/tail ìë™ ë¶„í• )
    use_langchain=False  # Trueë¡œ ë°”ê¾¸ë©´ LangChain ChatOpenAI ê²½ë¡œ ì‚¬ìš©
)

print("\n=== LLM Report ===\n")
print(report)
```

ì‹¤í–‰:
```bash
python examples/ask_once.py
```

### 2) Interactive chat: keep asking follow-up questions
ì•„ë˜ ìŠ¤ë‹ˆí«ì„ examples/chat_cli.pyë¡œ ì €ì¥í•˜ì„¸ìš”.
í•œ ë²ˆ ì „ì²˜ë¦¬í•œ DataFrameì„ ìœ ì§€í•œ ìƒíƒœì—ì„œ, ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ë°˜ë³µ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# examples/chat_cli.py
from modules.data_loader import load_cobot_data
from modules.preprocessor import preprocess_pipeline
from modules.llm_analyzer import analyze_with_llm, ping, quick_hello

def main():
    # Health checks (ì„ íƒ)
    try:
        print("Ping:", ping())
        print("Hello:", quick_hello())
    except Exception as e:
        print("[warn] LLM health-check failed:", e)

    # 1) Load & preprocess once
    DF_PATH = "data/cobot-sample.csv"  # <- ë°ì´í„° ê²½ë¡œë¥¼ ìƒí™©ì— ë§ê²Œ ìˆ˜ì •
    print(f"[info] Loading: {DF_PATH}")
    df = load_cobot_data(DF_PATH)
    print("[info] Preprocessing...")
    df_prep = preprocess_pipeline(df)
    print("[info] Ready. Type 'exit' to quit.")

    # 2) Chat loop
    try:
        while True:
            user = input("\nYou> ").strip()
            if not user:
                continue
            if user.lower() in {"exit", "quit", ":q"}:
                print("Bye!")
                break

            # ë°ì´í„°ì— ëŒ€í•œ ì¶”ê°€ ë¶„ì„ ì§€ì‹œë¥¼ promptë¡œ ì „ë‹¬
            answer = analyze_with_llm(
                df_prep,
                prompt=user,
                rows=10,            # í”„ë¦¬ë·° í¬ê¸°
                use_langchain=False # True -> LangChain ê²½ë¡œ
            )
            print("\nBot>\n" + answer)
    except KeyboardInterrupt:
        print("\n[Interrupted] Bye!")

if __name__ == "__main__":
    main()
```

ì‹¤í–‰:
```bash
python examples/chat_cli.py
```

### 3) Tips
- ë°ì´í„° ê²½ë¡œ: data/cobot-sample.csv ëŒ€ì‹  ì‹¤ì œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œë¥¼ ë„£ìœ¼ì„¸ìš”.
- íƒ€ì„ìŠ¤íƒ¬í”„ í¬ë§·: data_loader.load_cobot_dataê°€ YYYY-MM-DD HH-MM-SS-mmm(ms 3ìë¦¬ í¬í•¨) ë“± ë‹¤ì–‘í•œ í¬ë§·ì„ ê²¬ê³ í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸: preprocess_pipelineì€ ë²¡í„° ë¬¸ìì—´(q, tau, â€¦)ì„ *_0..*_5ë¡œ í™•ì¥í•˜ê³ , bool/ìˆ«ì ìºìŠ¤íŒ… í›„ ìˆ«ì ì»¬ëŸ¼ë§Œ ì •ê·œí™”í•©ë‹ˆë‹¤.
- ëª¨ë¸ ë³€ê²½: .envì˜ OPENAI_MODEL(LangChain) / OPENAI_CHAT_MODEL(OpenAI SDK)ë¡œ êµì²´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- í”„ë¦¬ë·° í¬ê¸°: rows ê°’ì„ ëŠ˜ë¦¬ë©´ LLMì— ë” ë§ì€ ìƒ˜í”Œì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆì§€ë§Œ, í† í° ë¹„ìš©ì´ ì¦ê°€í•©ë‹ˆë‹¤.
