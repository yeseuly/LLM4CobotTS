# LLM4CobotTS
LLM4CobotTS is a framework for analyzing collaborative robot (cobot) time-series data using Large Language Models (LLMs). This project explores natural languageâ€“driven interpretation, anomaly detection, and task-specific insights from multi-sensor robotic data streams.


### - Developers ğŸ‘©â€ğŸ’»

- **Ye-Seul Park**  
  âœ‰ï¸ [yeseuly777@gmail.com](mailto:yeseuly777@gmail.com)

- **Minseo Choi**  
  âœ‰ï¸ [minseo000624@gmail.com](mailto:minseo000624@gmail.com)

---

## ğŸ”§ Environment Variables

| Name | Default | Description |
|---|---:|---|
| `OPENAI_API_KEY` | â€” | OpenAI API Key (í•„ìˆ˜) |
| `OPENAI_MODEL` | `gpt-4o-mini` | LangChain `ChatOpenAI`ì— ì‚¬ìš©í•  ëª¨ë¸ |
| `OPENAI_CHAT_MODEL` | `gpt-4o` | OpenAI Python SDK(ì €ìˆ˜ì¤€)ì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ |
| `OPENAI_TEMPERATURE` | `0` | (LangChain) ì‘ë‹µ ì°½ì˜ì„± |
| `OPENAI_TOP_P` | `1.0` | (LangChain) nucleus sampling |
| `OPENAI_MAX_TOKENS` | `2048` | (LangChain) ìµœëŒ€ í† í° ìˆ˜ |

---
## ğŸ“¦ modules/preprocessor.py â€” Time-series Preprocessing

### Public API
| Function | Purpose | Key Params | Returns | Notes |
|---|---|---|---|---|
| `expand_vector_columns(df, candidates, expected_len=6, drop_original=False)` | ë¬¸ìì—´ ë²¡í„° ì»¬ëŸ¼("[...]")ì„ `*_0..*_k`ë¡œ í™•ì¥ | `candidates`: í™•ì¥ ëŒ€ìƒ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸<br>`expected_len`: ê¸°ëŒ€ ê¸¸ì´(ì˜ˆ: 6ì¶•). `None`ì´ë©´ ê°€ë³€ í—ˆìš©<br>`drop_original`: ì›ë³¸ ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±° ì—¬ë¶€ | `pd.DataFrame` | ë‚´ë¶€ì ìœ¼ë¡œ **ì¼ê´„ concat**ìœ¼ë¡œ ë¶™ì—¬ DataFrame ì¡°ê°í™” ë°©ì§€. ê°’ì€ `to_numeric`ìœ¼ë¡œ ìºìŠ¤íŒ… |
| `coerce_bools_and_numbers(df)` | `'True'/'False'` â†’ 1/0, ìˆ«ì ë¬¸ìì—´ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜ | â€” | `pd.DataFrame` | ëŒ€ê´„í˜¸(`[]`) ë²¡í„° ë¬¸ìì—´ì€ ì œì™¸í•˜ê³  ìºìŠ¤íŒ… |
| `normalize(df, exclude_cols=("timestamp",))` | int/floatë§Œ Minâ€“Max ì •ê·œí™” (bool ì œì™¸) | `exclude_cols`: ì •ê·œí™” ì œì™¸ ì»¬ëŸ¼ ëª©ë¡ | `pd.DataFrame` | ë¶„ëª¨ 0(ìƒìˆ˜ì—´)Â·ì „ë¶€ NaN â†’ 0ìœ¼ë¡œ ëŒ€ì²´ |
| `preprocess_pipeline(df)` | ê¶Œì¥ íŒŒì´í”„ë¼ì¸ (ë²¡í„° í™•ì¥ â†’ ìºìŠ¤íŒ… â†’ ì •ê·œí™”) | â€” | `pd.DataFrame` | ê¸°ë³¸ í›„ë³´: `q, qdot, qddot, qdes, qdotdes, qddotdes, p, ... , tau_ext, temperatures, ...` |

### Internal Helper
| Function | Purpose | Returns | Notes |
|---|---|---|---|
| `_safe_literal_eval_list(s)` | `"[1,2,3]"` ê°™ì€ ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ listë¡œ íŒŒì‹± | `list or None` | `ast.literal_eval` ê¸°ë°˜, ì‹¤íŒ¨ ì‹œ `None` |

---

## ğŸ“‚ modules/loader.py â€” Robust CSV Loader

### Public API
| Function | Purpose | Key Params | Returns | Notes |
|---|---|---|---|---|
| `load_cobot_data(filepath)` | CSV ë¡œë“œ + timestamp ê²¬ê³  íŒŒì‹± + ì •ë ¬ | `filepath`: íŒŒì¼ ê²½ë¡œ | `pd.DataFrame` | `timestamp` ì—†ìœ¼ë©´ ì²« ì»¬ëŸ¼â†’`timestamp`ë¡œ rename ë˜ëŠ” RangeIndex ìƒì„±. ë¯¸íŒŒì‹± ê±´ìˆ˜ ê²½ê³  ì¶œë ¥ |

### Internal Helpers
| Function | Purpose | Returns | Notes |
|---|---|---|---|
| `_safe_parse_timestamp(x)` | ë‹¤ì¤‘ í¬ë§· íŒŒì‹± ì‹œë„, ì‹¤íŒ¨ ì‹œ `NaT` | `pd.Timestamp` | ì¼ë°˜ í¬ë§· ë° ì»¤ìŠ¤í…€ í¬ë§· ì‹œë„ í›„ `errors="coerce"` |
| `_parse_ts_msec_style(ts)` | `YYYY-MM-DD HH-MM-SS-mmm`(ms 3ìë¦¬) ì²˜ë¦¬ | `pd.Timestamp or None` | msâ†’Î¼s ë³€í™˜í•´ ìƒì„± |
| `_try_formats(ts, fmts)` | ì§€ì • í¬ë§· ë¦¬ìŠ¤íŠ¸ ìˆœíšŒ íŒŒì‹± | `pd.Timestamp or None` | ì²« ì„±ê³µ í¬ë§· ë°˜í™˜ |

---

## ğŸ§  modules/analyzer.py â€” LLM-based Analysis

### Public API
| Function | Purpose | Key Params | Returns | Notes |
|---|---|---|---|---|
| `ping()` | LangChain LLM í—¬ìŠ¤ ì²´í¬ | â€” | `str` | ê°„ë‹¨í•œ ì‘ë‹µìœ¼ë¡œ ëª¨ë¸Â·ë„¤íŠ¸ì›Œí¬ í™•ì¸ |
| `analyze_with_llm(df, prompt=None, rows=8, use_langchain=False)` | ì „ì²˜ë¦¬ëœ TS í”„ë¦¬ë·°/ìŠ¤í‚¤ë§ˆë¥¼ LLMì— ì „ë‹¬í•´ ì¸ì‚¬ì´íŠ¸/ì´ìƒ íƒì§€ ë¦¬í¬íŠ¸ ìƒì„± | `prompt`: ì¶”ê°€ ì§€ì‹œë¬¸<br>`rows`: ë¯¸ë¦¬ë³´ê¸° ì´ í–‰ ìˆ˜ (head/tail ìë™ ë¶„í• )<br>`use_langchain`: `True`ë©´ LangChain, ê¸°ë³¸ì€ OpenAI SDK | `str` | ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë‚´ì¥. `temperature/top_p/max_tokens`ëŠ” `.env`ë¡œ ì œì–´ |
| `quick_hello()` | OpenAI SDK ê²½ëŸ‰ í˜¸ì¶œë¡œ í¬ë ˆë´ì…œÂ·ëª¨ë¸ í™•ì¸ | â€” | `str` | ë ˆì´íŠ¸ë¦¬ë°‹/ë„¤íŠ¸ì›Œí¬ ì²´í¬ìš© ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ |

### Internal / Infra
| Function | Purpose | Returns | Notes |
|---|---|---|---|
| `_df_preview(df, rows=8)` | head/tail ê¸°ë°˜ ì•ˆì „ í”„ë¦¬ë·° ë¬¸ìì—´ ìƒì„± | `str` | ëŒ€í˜• DFë„ í”„ë¡¬í”„íŠ¸ ë¶€ë‹´ ìµœì†Œí™” |
| `_schema_summary(df)` | ì»¬ëŸ¼ dtype + describe() ìš”ì•½ ë¬¸ìì—´ | `str` | ìˆ«ì ìœ„ì£¼ í†µê³„ í¬í•¨ |
| `_openai_chat(messages, model=None, **kwargs)` | OpenAI ì €ìˆ˜ì¤€ í˜¸ì¶œ + ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ | `str` | `tenacity`ë¡œ RateLimit/Timeout/APIError ëŒ€ì‘ |


---

## ğŸš€ Quick Start â€” Chat with your cobot data (using project modules)

ë³¸ ì˜ˆì œëŠ” ë ˆí¬ì— í¬í•¨ëœ ëª¨ë“ˆë§Œ ì‚¬ìš©í•˜ì—¬,  
1) ë°ì´í„°ë¥¼ ë¡œë“œ/ì „ì²˜ë¦¬í•˜ê³   
2) LLMì—ê²Œ ì§ˆë¬¸ì„ ë˜ì ¸  
3) ê²°ê³¼ë¥¼ ëŒ€í™”í˜•ìœ¼ë¡œ ë°›ì•„ë³´ëŠ” **ê°„ë‹¨ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤**ì…ë‹ˆë‹¤.

---

### 0) Install & Env

```bash
pip install -r requirements.txt
```

.env íŒŒì¼(ë£¨íŠ¸ ê²½ë¡œ)ì— OpenAI í‚¤ë¥¼ ë„£ì–´ì£¼ì„¸ìš”:
```ini
OPENAI_API_KEY=sk-********************************
# (ì„ íƒ) ëª¨ë¸/ìƒ˜í”Œë§ íŒŒë¼ë¯¸í„°
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_CHAT_MODEL=gpt-4o
# OPENAI_TEMPERATURE=0.3
# OPENAI_TOP_P=0.9
# OPENAI_MAX_TOKENS=1200
```

### 1) One-shot: Ask once about your dataset
ì•„ë˜ ìŠ¤ë‹ˆí«ì„ examples/ask_once.pyë¡œ ì €ì¥ í›„ ì‹¤í–‰í•˜ë©´,
ë°ì´í„°ë¥¼ ë¡œë“œâ†’ì „ì²˜ë¦¬í•œ ë’¤ í•œ ë²ˆ ì§ˆë¬¸í•˜ê³  ì‘ë‹µì„ ì¶œë ¥í•©ë‹ˆë‹¤.

```python
# examples/ask_once.py
from modules.data_loader import load_cobot_data
from modules.preprocessor import preprocess_pipeline
from modules.llm_analyzer import analyze_with_llm

# 1) Load & preprocess
DF_PATH = "data/cobot-sample.csv"  # <- ë°ì´í„° ê²½ë¡œë¥¼ ìƒí™©ì— ë§ê²Œ ìˆ˜ì •
df = load_cobot_data(DF_PATH)
df_prep = preprocess_pipeline(df)

# 2) Ask LLM about the dataset
question = "Identify anomalies in q/qdot and any signs of torque saturation."
report = analyze_with_llm(
    df_prep,
    prompt=question,
    rows=10,           # í”„ë¦¬ë·°ë¡œ ë³´ë‚¼ ì´ í–‰ ìˆ˜ (head/tail ìë™ ë¶„í• )
    use_langchain=False  # Trueë¡œ ë°”ê¾¸ë©´ LangChain ChatOpenAI ê²½ë¡œ ì‚¬ìš©
)

print("\n=== LLM Report ===\n")
print(report)
```

ì‹¤í–‰:
```bash
python examples/ask_once.py
```

### 2) Interactive chat: keep asking follow-up questions
ì•„ë˜ ìŠ¤ë‹ˆí«ì„ examples/chat_cli.pyë¡œ ì €ì¥í•˜ì„¸ìš”.
í•œ ë²ˆ ì „ì²˜ë¦¬í•œ DataFrameì„ ìœ ì§€í•œ ìƒíƒœì—ì„œ, ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ë°˜ë³µ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# examples/chat_cli.py
from modules.data_loader import load_cobot_data
from modules.preprocessor import preprocess_pipeline
from modules.llm_analyzer import analyze_with_llm, ping, quick_hello

def main():
    # Health checks (ì„ íƒ)
    try:
        print("Ping:", ping())
        print("Hello:", quick_hello())
    except Exception as e:
        print("[warn] LLM health-check failed:", e)

    # 1) Load & preprocess once
    DF_PATH = "data/cobot-sample.csv"  # <- ë°ì´í„° ê²½ë¡œë¥¼ ìƒí™©ì— ë§ê²Œ ìˆ˜ì •
    print(f"[info] Loading: {DF_PATH}")
    df = load_cobot_data(DF_PATH)
    print("[info] Preprocessing...")
    df_prep = preprocess_pipeline(df)
    print("[info] Ready. Type 'exit' to quit.")

    # 2) Chat loop
    try:
        while True:
            user = input("\nYou> ").strip()
            if not user:
                continue
            if user.lower() in {"exit", "quit", ":q"}:
                print("Bye!")
                break

            # ë°ì´í„°ì— ëŒ€í•œ ì¶”ê°€ ë¶„ì„ ì§€ì‹œë¥¼ promptë¡œ ì „ë‹¬
            answer = analyze_with_llm(
                df_prep,
                prompt=user,
                rows=10,            # í”„ë¦¬ë·° í¬ê¸°
                use_langchain=False # True -> LangChain ê²½ë¡œ
            )
            print("\nBot>\n" + answer)
    except KeyboardInterrupt:
        print("\n[Interrupted] Bye!")

if __name__ == "__main__":
    main()
```

ì‹¤í–‰:
```bash
python examples/chat_cli.py
```

### 3) Tips
- ë°ì´í„° ê²½ë¡œ: data/cobot-sample.csv ëŒ€ì‹  ì‹¤ì œ ë¡œê·¸ íŒŒì¼ ê²½ë¡œë¥¼ ë„£ìœ¼ì„¸ìš”.
- íƒ€ì„ìŠ¤íƒ¬í”„ í¬ë§·: data_loader.load_cobot_dataê°€ YYYY-MM-DD HH-MM-SS-mmm(ms 3ìë¦¬ í¬í•¨) ë“± ë‹¤ì–‘í•œ í¬ë§·ì„ ê²¬ê³ í•˜ê²Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
- ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸: preprocess_pipelineì€ ë²¡í„° ë¬¸ìì—´(q, tau, â€¦)ì„ *_0..*_5ë¡œ í™•ì¥í•˜ê³ , bool/ìˆ«ì ìºìŠ¤íŒ… í›„ ìˆ«ì ì»¬ëŸ¼ë§Œ ì •ê·œí™”í•©ë‹ˆë‹¤.
- ëª¨ë¸ ë³€ê²½: .envì˜ OPENAI_MODEL(LangChain) / OPENAI_CHAT_MODEL(OpenAI SDK)ë¡œ êµì²´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- í”„ë¦¬ë·° í¬ê¸°: rows ê°’ì„ ëŠ˜ë¦¬ë©´ LLMì— ë” ë§ì€ ìƒ˜í”Œì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆì§€ë§Œ, í† í° ë¹„ìš©ì´ ì¦ê°€í•©ë‹ˆë‹¤.
